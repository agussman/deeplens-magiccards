{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start by retrieving some Magic card images using the Scryfall API\n",
    "# https://scryfall.com/docs/api\n",
    "# We'll be using the Scryfall python library\n",
    "# https://github.com/NandaScott/Scrython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from requests.exceptions import TooManyRedirects, ReadTimeout, ConnectionError\n",
    "import json\n",
    "import pprint\n",
    "import time\n",
    "import shutil\n",
    "import os\n",
    "import os.path\n",
    "import glob\n",
    "import csv\n",
    "from PIL import Image\n",
    "import random\n",
    "import numpy as np\n",
    "import errno\n",
    "import mxnet as mx\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "URL='https://api.scryfall.com'\n",
    "OUTDIR='/Users/agussman/Documents/DeepLens/deeplens-magiccards/data'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get('https://api.scryfall.com/cards/search?order=set&q=e:dom')\n",
    "# TODO: Support Scryfall pagination: https://scryfall.com/docs/api/lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = r.json()['data']\n",
    "for result in results[:1000]:\n",
    "    #card = result\n",
    "    #if 'all_parts' in result\n",
    "    #print(result['image_uris']['png'])\n",
    "    time.sleep(0.25)\n",
    "    image_url = result['image_uris']['png']\n",
    "    filename = \"{}_{num:03d}.png\".format(result['set'], num=int(result['collector_number']))\n",
    "    filename = os.path.join(OUTDIR, result['set'], filename)\n",
    "    print(filename)\n",
    "    print(\"{} -> {}\".format(image_url, filename))\n",
    "    \n",
    "    r = requests.get(image_url, stream=True)\n",
    "    \n",
    "    with open(filename, 'wb') as fd:\n",
    "        for chunk in r.iter_content(chunk_size=128):\n",
    "            fd.write(chunk)\n",
    "    \n",
    "    '''\n",
    "    if r.status_code == 200:\n",
    "        with open(os.path.join(OUTDIR, result['set'], filename), 'wb') as out_file:\n",
    "            shutil.copyfileobj(response.raw(), out_file)\n",
    "    else:\n",
    "        print(\"Nope. {}\".format(response.status_code))\n",
    "    '''\n",
    "    \n",
    "    \n",
    "#pprint.pprint(results[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next let's download some pictures of tables\n",
    "# TODO: Don't download HTML as a JPG\n",
    "table_list_url = 'http://image-net.org/api/text/imagenet.synset.geturls?wnid=n03201035'\n",
    "r = requests.get(table_list_url)\n",
    "\n",
    "file_urls = r.text.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num, table_url in enumerate(file_urls[100:]):\n",
    "    print(num, table_url)\n",
    "    time.sleep(0.25)\n",
    "    filename = \"{num:003d}_{original}\".format(num=num, original=os.path.basename(table_url))\n",
    "    filename = os.path.join(OUTDIR, 'tables', filename)\n",
    "    print(filename)\n",
    "    print(\"{} -> {}\".format(table_url, filename))\n",
    "    \n",
    "    try:\n",
    "        r = requests.get(table_url, stream=True, timeout=1)\n",
    "        if r.status_code == 200:\n",
    "            with open(filename, 'wb') as fd:\n",
    "                for chunk in r.iter_content(chunk_size=128):\n",
    "                    fd.write(chunk)\n",
    "        else:\n",
    "            print(\"SKIP: Problem downloading: {}\".format(r.status_code))\n",
    "    except TooManyRedirects:\n",
    "        print(\"SKIP: TooManyRedirects\")\n",
    "    except ReadTimeout:\n",
    "        print(\"SKIP: ReadTimeout\")\n",
    "    except ConnectionError:\n",
    "        print(\"SKIP: ConnectionError\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose_images(foreground_path, background_path):\n",
    "    # Make sure the foreground path is valid and open the image\n",
    "    assert os.path.exists(foreground_path), 'image path does not exist: {}'.format(foreground_path)\n",
    "    assert os.path.splitext(foreground_path)[1].lower() == '.png', 'foreground must be a .png file'\n",
    "    foreground = Image.open(foreground_path)\n",
    "    foreground_alpha = np.array(foreground.getchannel(3))\n",
    "    assert np.any(foreground_alpha == 0), 'foreground needs to have some transparency: {}'.format(foreground_path)\n",
    "    \n",
    "    # Make sure the background path is valid and open the image\n",
    "    assert os.path.exists(background_path), 'image path does not exist: {}'.format(background_path)\n",
    "    assert os.path.splitext(background_path)[1].lower() in ['.png', '.jpg', 'jpeg'], \\\n",
    "        'foreground must be a .png or .jpg file: {}'.format(foreground_path)\n",
    "    background = Image.open(background_path)\n",
    "    background = background.convert('RGBA')\n",
    "    \n",
    "    # Rotate the foreground\n",
    "    angle_degrees = random.randint(0, 359)\n",
    "    # TODO: try\n",
    "    # 1/4 of the time keep it close to center\n",
    "    # 1/4 of the time keep it 90 to 180\n",
    "    # 1/4 of the time -180 to 180\n",
    "    # 1/4 of the time anywhere\n",
    "    foreground = foreground.rotate(angle_degrees, resample=Image.BICUBIC, expand=True)\n",
    "    \n",
    "    # Scale the foreground\n",
    "    max_xy_position = (background.size[0] - foreground.size[0], background.size[1] - foreground.size[1])\n",
    "    while (max_xy_position[0] < 0 or max_xy_position[1] < 0):\n",
    "        print(\"Scaling down...\")\n",
    "        scale = random.random() * .5 + .5 # Pick something between .5 and 1\n",
    "        new_size = (int(foreground.size[0] * scale), int(foreground.size[1] * scale))\n",
    "        foreground = foreground.resize(new_size, resample=Image.BICUBIC)\n",
    "        max_xy_position = (background.size[0] - foreground.size[0], background.size[1] - foreground.size[1])\n",
    "    \n",
    "    \n",
    "    # Add any other transformations here...\n",
    "    \n",
    "    # Choose a random x,y position for the foreground\n",
    "    max_xy_position = (background.size[0] - foreground.size[0], background.size[1] - foreground.size[1])\n",
    "    assert max_xy_position[0] >= 0 and max_xy_position[1] >= 0, \\\n",
    "        'foreground {} is to big for the background {}'.format(foreground_path, background_path)\n",
    "    paste_position = (random.randint(0, max_xy_position[0]), random.randint(0, max_xy_position[1]))\n",
    "    \n",
    "    # Create a new foreground image as large as the background and paste it on top\n",
    "    new_foreground = Image.new('RGBA', background.size, color = (0, 0, 0, 0))\n",
    "    new_foreground.paste(foreground, paste_position)\n",
    "        \n",
    "    # Extract the alpha channel from the foreground and paste it into a new image the size of the background\n",
    "    alpha_mask = foreground.getchannel(3)\n",
    "    new_alpha_mask = Image.new('L', background.size, color=0)\n",
    "    new_alpha_mask.paste(alpha_mask, paste_position)\n",
    "    composite = Image.composite(new_foreground, background, new_alpha_mask)\n",
    "    \n",
    "    # Grab the alpha pixels above a specified threshold\n",
    "    alpha_threshold = 200\n",
    "    mask_arr = np.array(np.greater(np.array(new_alpha_mask), alpha_threshold), dtype=np.uint8)\n",
    "    hard_mask = Image.fromarray(np.uint8(mask_arr) * 255, 'L')\n",
    "    \n",
    "    # Get the smallest & largest non-zero values in each dimension and calculate the bounding box\n",
    "    nz = np.nonzero(hard_mask)\n",
    "    bbox = [np.min(nz[0]), np.min(nz[1]), np.max(nz[0]), np.max(nz[1])] \n",
    "\n",
    "    return composite, hard_mask, bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following https://www.immersivelimit.com/tutorials/composing-images-with-python-for-synthetic-datasets\n",
    "# sometimes this throws a 'composite not defined' error?\n",
    "foreground_dir = os.path.join(OUTDIR, 'dom')\n",
    "background_dir = os.path.join(OUTDIR, 'tables')\n",
    "\n",
    "output_dir = os.path.join(OUTDIR, 'generated')\n",
    "\n",
    "foregrounds = glob.glob(foreground_dir+\"/*.png\")\n",
    "backgrounds = glob.glob(background_dir+\"/*.jpg\")\n",
    "\n",
    "# Create a list to keep track of images and mask annotations\n",
    "csv_lines = []\n",
    "\n",
    "# Generate 5 new images\n",
    "n_generated_images = 1500\n",
    "for i in range(n_generated_images):\n",
    "    foreground_path = random.choice(foregrounds)\n",
    "    background_path = random.choice(backgrounds)\n",
    "    try:\n",
    "        composite, mask, bbox = compose_images(foreground_path, background_path)\n",
    "    except OSError:\n",
    "        next\n",
    "        \n",
    "    \n",
    "    composite_path = os.path.join(output_dir, 'image_{0:04d}.png'.format(i))\n",
    "    composite.save(composite_path)\n",
    "    \n",
    "    #mask_path = os.path.join(output_dir, 'mask_{0:04d}.png'.format(i))\n",
    "    #mask.save(mask_path)\n",
    "    \n",
    "    width, height = composite.size\n",
    "    csv_lines.append([width, height, bbox, composite_path])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating test data\n",
    "test_dir = os.path.join(OUTDIR, 'test')\n",
    "\n",
    "# Generate 5 new images\n",
    "for i in range(10):\n",
    "    foreground_path = random.choice(foregrounds)\n",
    "    background_path = random.choice(backgrounds)\n",
    "    try:\n",
    "        composite, mask, bbox = compose_images(foreground_path, background_path)\n",
    "    except OSError:\n",
    "        next\n",
    "\n",
    "    composite_path = os.path.join(test_dir, 'image_{0:04d}.png'.format(i))\n",
    "    composite.save(composite_path)\n",
    "    \n",
    "    mask_path = os.path.join(output_dir, 'mask_{0:04d}.png'.format(i))\n",
    "    mask.save(mask_path)\n",
    "    \n",
    "    width, height = composite.size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpi = 80\n",
    "margin = 0.05 # (5% of the width/height of the figure...)\n",
    "#xpixels, ypixels = 800, 800\n",
    "\n",
    "# Make a figure big enough to accomodate an axis of xpixels by ypixels\n",
    "# as well as the ticklabels, etc...\n",
    "figsize = (1 + margin) * height / dpi, (1 + margin) * width / dpi\n",
    "\n",
    "fig = plt.figure(figsize=figsize, dpi=dpi)\n",
    "# Make the axis the right size...\n",
    "ax = fig.add_axes([margin, margin, 1 - 2*margin, 1 - 2*margin])\n",
    "\n",
    "ax.imshow(composite, interpolation='none')\n",
    "ymin, xmin, ymax, xmax = bbox\n",
    "rect = plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, fill=False, edgecolor=(1, 0, 0), linewidth=3)\n",
    "ax.add_patch(rect)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the annotations csv\n",
    "# Using file layout from here: https://mxnet.incubator.apache.org/versions/master/api/python/image/image.html\n",
    "# id header_width object_width object_id, xmin, ymin, xmax, ymax image_path\n",
    "annotations_csv_path = os.path.join(OUTDIR, 'train.lst')\n",
    "with open(annotations_csv_path, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile, delimiter='\\t', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "    for idx, csv_line in enumerate(csv_lines):\n",
    "        width = csv_line[0]\n",
    "        height = csv_line[1]\n",
    "        bbox = csv_line[2]\n",
    "        image_path = csv_line[3]\n",
    "        outrow = [idx, 4, 5, width, height, idx, bbox[0] / height, bbox[1] / width, bbox[2] / height, bbox[3] / width, image_path]\n",
    "        writer.writerow(outrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32 # Number of examples per batch, some examples are 4, pikachu uses 32\n",
    "data_shape = 256 # Data shape in (channels, height, width) format. For now, only RGB image with 3 channels is supported.\n",
    "                 # some example had 224, but pikachu example uses 256\n",
    "data_iter = mx.image.ImageDetIter(batch_size=batch_size, data_shape=(3, data_shape, data_shape),\n",
    "                                      path_imglist=OUTDIR+'/train.lst', path_root='/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gluon.mxnet.io/chapter08_computer-vision/object-detection.html\n",
    "data_iter.reset()\n",
    "batch = data_iter.next()\n",
    "#print(batch)\n",
    "#data_shape = 256\n",
    "\n",
    "i = 9\n",
    "\n",
    "img = batch.data[0][i].asnumpy()  # grab the first image, convert to numpy array\n",
    "img = img.transpose((1, 2, 0))  # we want channel to be the last dimension\n",
    "#img += np.array([123, 117, 104])\n",
    "img = img.astype(np.uint8)  # use uint8 (0-255)\n",
    "\n",
    "# Create figure and axes\n",
    "fig,ax = plt.subplots(1)\n",
    "ax.imshow(img)\n",
    "\n",
    "# draw bounding boxes on image\n",
    "for label in batch.label[0][i].asnumpy():\n",
    "    if label[0] < 0:\n",
    "        print(\"MISSING LABEL????\")\n",
    "        break\n",
    "    print(label)\n",
    "    ymin, xmin, ymax, xmax = [int(x * data_shape) for x in label[1:5]]\n",
    "    #xmin, ymin, xmax, ymax = label[1:5]\n",
    "    # scale to new size\n",
    "    #xmin, ymin, xmax, ymax = 58, 179, 150, 279\n",
    "    #xmin, ymin, xmax, ymax = label[, 179, 150, 279\n",
    "    rect = plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, fill=False, edgecolor=(1, 0, 0), linewidth=3)\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter.reset()\n",
    "batch = data_iter.next()\n",
    "data = batch.data[0]\n",
    "#for i in range(4):\n",
    "#    plt.subplot(1,4,i+1)\n",
    "#    plt.imshow(data[i].asnumpy().astype(np.uint8).transpose((1,2,0)))\n",
    "plt.imshow(data[1].asnumpy().astype(np.uint8).transpose((1,2,0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working forward from https://gluon.mxnet.io/chapter08_computer-vision/object-detection.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "from mxnet import nd\n",
    "from mxnet.contrib.ndarray import MultiBoxPrior\n",
    "\n",
    "n = 40\n",
    "# shape: batch x channel x height x weight\n",
    "x = nd.random_uniform(shape=(1, 3, n, n))\n",
    "\n",
    "y = MultiBoxPrior(x, sizes=[.5, .25, .1], ratios=[1, 2, .5])\n",
    "\n",
    "# the first anchor box generated for pixel at (20,20)\n",
    "# its format is (x_min, y_min, x_max, y_max)\n",
    "boxes = y.reshape((n, n, -1, 4))\n",
    "print('The first anchor box at row 21, column 21:', boxes[20, 20, 0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def box_to_rect(box, color, linewidth=3):\n",
    "    \"\"\"convert an anchor box to a matplotlib rectangle\"\"\"\n",
    "    box = box.asnumpy()\n",
    "    return plt.Rectangle(\n",
    "        (box[0], box[1]), (box[2]-box[0]), (box[3]-box[1]),\n",
    "        fill=False, edgecolor=color, linewidth=linewidth)\n",
    "colors = ['blue', 'green', 'red', 'black', 'magenta']\n",
    "plt.imshow(nd.ones((n, n, 3)).asnumpy())\n",
    "anchors = boxes[20, 20, :, :]\n",
    "for i in range(anchors.shape[0]):\n",
    "    plt.gca().add_patch(box_to_rect(anchors[i,:]*n, colors[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.gluon import nn\n",
    "def class_predictor(num_anchors, num_classes):\n",
    "    \"\"\"return a layer to predict classes\"\"\"\n",
    "    return nn.Conv2D(num_anchors * (num_classes + 1), 3, padding=1)\n",
    "\n",
    "cls_pred = class_predictor(5, 10)\n",
    "cls_pred.initialize()\n",
    "x = nd.zeros((2, 3, 20, 20))\n",
    "print('Class prediction', cls_pred(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_predictor(num_anchors):\n",
    "    \"\"\"return a layer to predict delta locations\"\"\"\n",
    "    return nn.Conv2D(num_anchors * 4, 3, padding=1)\n",
    "\n",
    "box_pred = box_predictor(10)\n",
    "box_pred.initialize()\n",
    "x = nd.zeros((2, 3, 20, 20))\n",
    "print('Box prediction', box_pred(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def down_sample(num_filters):\n",
    "    \"\"\"stack two Conv-BatchNorm-Relu blocks and then a pooling layer\n",
    "    to halve the feature size\"\"\"\n",
    "    out = nn.HybridSequential()\n",
    "    for _ in range(2):\n",
    "        out.add(nn.Conv2D(num_filters, 3, strides=1, padding=1))\n",
    "        out.add(nn.BatchNorm(in_channels=num_filters))\n",
    "        out.add(nn.Activation('relu'))\n",
    "    out.add(nn.MaxPool2D(2))\n",
    "    return out\n",
    "\n",
    "blk = down_sample(10)\n",
    "blk.initialize()\n",
    "x = nd.zeros((2, 3, 20, 20))\n",
    "print('Before', x.shape, 'after', blk(x).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a certain feature map with 20x20 spatial shape\n",
    "feat1 = nd.zeros((2, 8, 20, 20))\n",
    "print('Feature map 1', feat1.shape)\n",
    "cls_pred1 = class_predictor(5, 10)\n",
    "cls_pred1.initialize()\n",
    "y1 = cls_pred1(feat1)\n",
    "print('Class prediction for feature map 1', y1.shape)\n",
    "# down-sample\n",
    "ds = down_sample(16)\n",
    "ds.initialize()\n",
    "feat2 = ds(feat1)\n",
    "print('Feature map 2', feat2.shape)\n",
    "cls_pred2 = class_predictor(3, 10)\n",
    "cls_pred2.initialize()\n",
    "y2 = cls_pred2(feat2)\n",
    "print('Class prediction for feature map 2', y2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_prediction(pred):\n",
    "    return nd.flatten(nd.transpose(pred, axes=(0, 2, 3, 1)))\n",
    "\n",
    "def concat_predictions(preds):\n",
    "    return nd.concat(*preds, dim=1)\n",
    "\n",
    "flat_y1 = flatten_prediction(y1)\n",
    "print('Flatten class prediction 1', flat_y1.shape)\n",
    "flat_y2 = flatten_prediction(y2)\n",
    "print('Flatten class prediction 2', flat_y2.shape)\n",
    "print('Concat class predictions', concat_predictions([flat_y1, flat_y2]).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO This needs to be made something actual?\n",
    "# from the text: Common choices follow the architectures of the state-of-the-art convolution neural \n",
    "# networks for image classification. For demonstration purpose, we just stack several down sampling \n",
    "# blocks to form the body network.\n",
    "from mxnet import gluon\n",
    "def body():\n",
    "    \"\"\"return the body network\"\"\"\n",
    "    out = nn.HybridSequential()\n",
    "    for nfilters in [16, 32, 64]:\n",
    "        out.add(down_sample(nfilters))\n",
    "    return out\n",
    "\n",
    "bnet = body()\n",
    "bnet.initialize()\n",
    "x = nd.zeros((2, 3, 256, 256))\n",
    "print('Body network', [y.shape for y in bnet(x)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toy_ssd_model(num_anchors, num_classes):\n",
    "    \"\"\"return SSD modules\"\"\"\n",
    "    downsamples = nn.Sequential()\n",
    "    class_preds = nn.Sequential()\n",
    "    box_preds = nn.Sequential()\n",
    "\n",
    "    downsamples.add(down_sample(128))\n",
    "    downsamples.add(down_sample(128))\n",
    "    downsamples.add(down_sample(128))\n",
    "\n",
    "    for scale in range(5):\n",
    "        class_preds.add(class_predictor(num_anchors, num_classes))\n",
    "        box_preds.add(box_predictor(num_anchors))\n",
    "\n",
    "    return body(), downsamples, class_preds, box_preds\n",
    "\n",
    "print(toy_ssd_model(5, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toy_ssd_forward(x, body, downsamples, class_preds, box_preds, sizes, ratios):\n",
    "    # extract feature with the body network\n",
    "    x = body(x)\n",
    "\n",
    "    # for each scale, add anchors, box and class predictions,\n",
    "    # then compute the input to next scale\n",
    "    default_anchors = []\n",
    "    predicted_boxes = []\n",
    "    predicted_classes = []\n",
    "\n",
    "    for i in range(5):\n",
    "        default_anchors.append(MultiBoxPrior(x, sizes=sizes[i], ratios=ratios[i]))\n",
    "        predicted_boxes.append(flatten_prediction(box_preds[i](x)))\n",
    "        predicted_classes.append(flatten_prediction(class_preds[i](x)))\n",
    "        if i < 3:\n",
    "            x = downsamples[i](x)\n",
    "        elif i == 3:\n",
    "            # simply use the pooling layer\n",
    "            x = nd.Pooling(x, global_pool=True, pool_type='max', kernel=(4, 4))\n",
    "\n",
    "    return default_anchors, predicted_classes, predicted_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import gluon\n",
    "class ToySSD(gluon.Block):\n",
    "    def __init__(self, num_classes, **kwargs):\n",
    "        super(ToySSD, self).__init__(**kwargs)\n",
    "        # anchor box sizes for 4 feature scales\n",
    "        self.anchor_sizes = [[.2, .272], [.37, .447], [.54, .619], [.71, .79], [.88, .961]]\n",
    "        # anchor box ratios for 4 feature scales\n",
    "        self.anchor_ratios = [[1, 2, .5]] * 5\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        with self.name_scope():\n",
    "            self.body, self.downsamples, self.class_preds, self.box_preds = toy_ssd_model(4, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        default_anchors, predicted_classes, predicted_boxes = toy_ssd_forward(x, self.body, self.downsamples,\n",
    "            self.class_preds, self.box_preds, self.anchor_sizes, self.anchor_ratios)\n",
    "        # we want to concatenate anchors, class predictions, box predictions from different layers\n",
    "        anchors = concat_predictions(default_anchors)\n",
    "        box_preds = concat_predictions(predicted_boxes)\n",
    "        class_preds = concat_predictions(predicted_classes)\n",
    "        # it is better to have class predictions reshaped for softmax computation\n",
    "        class_preds = nd.reshape(class_preds, shape=(0, -1, self.num_classes + 1))\n",
    "\n",
    "        return anchors, class_preds, box_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a ToySSD network with 10 classes\n",
    "net = ToySSD(2)\n",
    "net.initialize()\n",
    "x = nd.zeros((1, 3, 256, 256))\n",
    "default_anchors, class_predictions, box_predictions = net(x)\n",
    "print('Outputs:', 'anchors', default_anchors.shape, 'class prediction', class_predictions.shape, 'box prediction', box_predictions.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['magic_card']\n",
    "num_class = len(class_names)\n",
    "train_data = data_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.contrib.ndarray import MultiBoxTarget\n",
    "def training_targets(default_anchors, class_predicts, labels):\n",
    "    class_predicts = nd.transpose(class_predicts, axes=(0, 2, 1))\n",
    "    z = MultiBoxTarget(*[default_anchors, labels, class_predicts])\n",
    "    box_target = z[0]  # box offset target for (x, y, width, height)\n",
    "    box_mask = z[1]  # mask is used to ignore box offsets we don't want to penalize, e.g. negative samples\n",
    "    cls_target = z[2]  # cls_target is an array of labels for all anchors boxes\n",
    "    return box_target, box_mask, cls_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import gluon\n",
    "class FocalLoss(gluon.loss.Loss):\n",
    "    def __init__(self, axis=-1, alpha=0.25, gamma=2, batch_axis=0, **kwargs):\n",
    "        super(FocalLoss, self).__init__(None, batch_axis, **kwargs)\n",
    "        self._axis = axis\n",
    "        self._alpha = alpha\n",
    "        self._gamma = gamma\n",
    "\n",
    "    def hybrid_forward(self, F, output, label):\n",
    "        output = F.softmax(output)\n",
    "        pt = F.pick(output, label, axis=self._axis, keepdims=True)\n",
    "        loss = -self._alpha * ((1 - pt) ** self._gamma) * F.log(pt)\n",
    "        return F.mean(loss, axis=self._batch_axis, exclude=True)\n",
    "\n",
    "# cls_loss = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "cls_loss = FocalLoss()\n",
    "print(cls_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmoothL1Loss(gluon.loss.Loss):\n",
    "    def __init__(self, batch_axis=0, **kwargs):\n",
    "        super(SmoothL1Loss, self).__init__(None, batch_axis, **kwargs)\n",
    "\n",
    "    def hybrid_forward(self, F, output, label, mask):\n",
    "        loss = F.smooth_l1((output - label) * mask, scalar=1.0)\n",
    "        return F.mean(loss, self._batch_axis, exclude=True)\n",
    "\n",
    "box_loss = SmoothL1Loss()\n",
    "print(box_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_metric = mx.metric.Accuracy()\n",
    "box_metric = mx.metric.MAE()  # measure absolute difference between prediction and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet import nd\n",
    "### Set context for training\n",
    "ctx = mx.gpu()  # it may takes too long to train using CPU\n",
    "try:\n",
    "    _ = nd.zeros(1, ctx=ctx)\n",
    "    # pad label for cuda implementation\n",
    "    train_data.reshape(label_shape=(3, 5))\n",
    "    train_data = test_data.sync_label_shape(train_data)\n",
    "except mx.base.MXNetError as err:\n",
    "    print('No GPU enabled, fall back to CPU, sit back and be patient...')\n",
    "    ctx = mx.cpu()\n",
    "\n",
    "# This reports no GPU...\n",
    "# Looks like I'd need to follow instructions here to get it to work:\n",
    "# https://mxnet.incubator.apache.org/install/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = ToySSD(num_class)\n",
    "net.initialize(mx.init.Xavier(magnitude=2), ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.collect_params().reset_ctx(ctx)\n",
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': 0.1, 'wd': 5e-4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DID YOU SET train_data above?\n",
    "#epochs = 150  # set larger to get better performance\n",
    "epochs = 50\n",
    "log_interval = 20\n",
    "from_scratch = True  # set to True to train from scratch\n",
    "if from_scratch:\n",
    "    start_epoch = 0\n",
    "else:\n",
    "    start_epoch = 148\n",
    "    pretrained = 'ssd_pretrained.params'\n",
    "    sha1 = 'fbb7d872d76355fff1790d864c2238decdb452bc'\n",
    "    url = 'https://apache-mxnet.s3-accelerate.amazonaws.com/gluon/models/ssd_pikachu-fbb7d872.params'\n",
    "    if not osp.exists(pretrained) or not verified(pretrained, sha1):\n",
    "        print('Downloading', pretrained, url)\n",
    "        download(url, fname=pretrained, overwrite=True)\n",
    "    net.load_params(pretrained, ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from mxnet import autograd as ag\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    # reset iterator and tick\n",
    "    train_data.reset()\n",
    "    cls_metric.reset()\n",
    "    box_metric.reset()\n",
    "    tic = time.time()\n",
    "    # iterate through all batch\n",
    "    for i, batch in enumerate(train_data):\n",
    "        btic = time.time()\n",
    "        # record gradients\n",
    "        with ag.record():\n",
    "            x = batch.data[0].as_in_context(ctx)\n",
    "            y = batch.label[0].as_in_context(ctx)\n",
    "            default_anchors, class_predictions, box_predictions = net(x)\n",
    "            box_target, box_mask, cls_target = training_targets(default_anchors, class_predictions, y)\n",
    "            # losses\n",
    "            loss1 = cls_loss(class_predictions, cls_target)\n",
    "            loss2 = box_loss(box_predictions, box_target, box_mask)\n",
    "            # sum all losses\n",
    "            loss = loss1 + loss2\n",
    "            # backpropagate\n",
    "            loss.backward()\n",
    "        # apply\n",
    "        trainer.step(batch_size)\n",
    "        # update metrics\n",
    "        cls_metric.update([cls_target], [nd.transpose(class_predictions, (0, 2, 1))])\n",
    "        box_metric.update([box_target], [box_predictions * box_mask])\n",
    "        if (i + 1) % log_interval == 0:\n",
    "            name1, val1 = cls_metric.get()\n",
    "            name2, val2 = box_metric.get()\n",
    "            print('[Epoch %d Batch %d] speed: %f samples/s, training: %s=%f, %s=%f'\n",
    "                  %(epoch ,i, batch_size/(time.time()-btic), name1, val1, name2, val2))\n",
    "\n",
    "    # end of epoch logging\n",
    "    name1, val1 = cls_metric.get()\n",
    "    name2, val2 = box_metric.get()\n",
    "    print('[Epoch %d] training: %s=%f, %s=%f'%(epoch, name1, val1, name2, val2))\n",
    "    print('[Epoch %d] time cost: %f'%(epoch, time.time()-tic))\n",
    "\n",
    "print('{} training images, {} epochs (%f)'.format(n_generated_images, epochs, time.time()-tic))    \n",
    "# we can save the trained parameters to disk\n",
    "net.save_params('ssd_%d.params' % epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "import numpy as np\n",
    "import cv2\n",
    "def preprocess(image):\n",
    "    \"\"\"Takes an image and apply preprocess\"\"\"\n",
    "    # resize to data_shape\n",
    "    image = cv2.resize(image, (data_shape, data_shape))\n",
    "    # swap BGR to RGB\n",
    "    image = image[:, :, (2, 1, 0)]\n",
    "    # convert to float before subtracting mean\n",
    "    image = image.astype(np.float32)\n",
    "    # subtract mean\n",
    "    image -= np.array([123, 117, 104])\n",
    "    # organize as [batch-channel-height-width]\n",
    "    image = np.transpose(image, (2, 0, 1))\n",
    "    image = image[np.newaxis, :]\n",
    "    # convert to ndarray\n",
    "    image = nd.array(image)\n",
    "    return image\n",
    "i = 0\n",
    "image = cv2.imread(os.path.join(test_dir, 'image_{0:04d}.png'.format(i)))\n",
    "x = preprocess(image)\n",
    "print('x', x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if pre-trained model is provided, we can load it\n",
    "# net.load_params('ssd_%d.params' % epochs, ctx)\n",
    "anchors, cls_preds, box_preds = net(x.as_in_context(ctx))\n",
    "print('anchors', anchors)\n",
    "print('class predictions', cls_preds)\n",
    "print('box delta predictions', box_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mxnet.contrib.ndarray import MultiBoxDetection\n",
    "# convert predictions to probabilities using softmax\n",
    "cls_probs = nd.SoftmaxActivation(nd.transpose(cls_preds, (0, 2, 1)), mode='channel')\n",
    "# apply shifts to anchors boxes, non-maximum-suppression, etc...\n",
    "output = MultiBoxDetection(*[cls_probs, box_preds, anchors], force_suppress=True, clip=False)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(img, out, thresh=0.5):\n",
    "    import random\n",
    "    import matplotlib as mpl\n",
    "    mpl.rcParams['figure.figsize'] = (10,10)\n",
    "    pens = dict()\n",
    "    plt.clf()\n",
    "    plt.imshow(img)\n",
    "    for det in out:\n",
    "        cid = int(det[0])\n",
    "        if cid < 0:\n",
    "            continue\n",
    "        score = det[1]\n",
    "        if score < thresh:\n",
    "            continue\n",
    "        if cid not in pens:\n",
    "            pens[cid] = (random.random(), random.random(), random.random())\n",
    "        scales = [img.shape[1], img.shape[0]] * 2\n",
    "        xmin, ymin, xmax, ymax = [int(p * s) for p, s in zip(det[2:6].tolist(), scales)]\n",
    "        rect = plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin, fill=False,\n",
    "                             edgecolor=pens[cid], linewidth=3)\n",
    "        plt.gca().add_patch(rect)\n",
    "        text = class_names[cid]\n",
    "        plt.gca().text(xmin, ymin-2, '{:s} {:.3f}'.format(text, score),\n",
    "                       bbox=dict(facecolor=pens[cid], alpha=0.5),\n",
    "                       fontsize=12, color='white')\n",
    "    plt.show()\n",
    "\n",
    "thresh = 0.45\n",
    "#thresh = 0.55\n",
    "display(image[:, :, (2, 1, 0)], output[0].asnumpy(), thresh=thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the model to SageMaker\n",
    "\n",
    "We're following the instructions from [here](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/advanced_functionality/mxnet_mnist_byom/mxnet_mnist.ipynb) starting with **Set up hosting for the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: THis? https://mxnet.incubator.apache.org/tutorials/gluon/save_load_params.html\n",
    "\n",
    "import os\n",
    "import json\n",
    "#os.mkdir('model')\n",
    "\n",
    "savedir = 'data/model'\n",
    "\n",
    "#net.save_checkpoint(savedir + '/model', 0000)\n",
    "#with open ( savedir + '/model-shapes.json', \"w\") as shapes:\n",
    "#    json.dump([{\"shape\": net.data_shapes[0][1], \"name\": \"data\"}], shapes)\n",
    "\n",
    "net.export(savedir, epochs)\n",
    "\n",
    "import tarfile\n",
    "def flatten(tarinfo):\n",
    "    tarinfo.name = os.path.basename(tarinfo.name)\n",
    "    return tarinfo\n",
    "\n",
    "tar = tarfile.open(\"data/model.tar.gz\", \"w:gz\")\n",
    "tar.add(savedir, filter=flatten)\n",
    "tar.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "query = input(\"Type the name of the set: \")\n",
    "\n",
    "time.sleep(0.05)\n",
    "sets = scrython.sets.Sets()\n",
    "\n",
    "for i in range(sets.data_length()):\n",
    "    if sets.set_name(i) == query:\n",
    "        print(\"Set code:\", sets.set_code(i).upper())\n",
    "        break\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
